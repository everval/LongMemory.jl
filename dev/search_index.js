var documenterSearchIndex = {"docs":
[{"location":"parametric/","page":"Parameter Estimation","title":"Parameter Estimation","text":"CurrentModule = LongMemory","category":"page"},{"location":"parametric/#Parametric-Estimators-for-Long-Memory","page":"Parameter Estimation","title":"Parametric Estimators for Long Memory","text":"","category":"section"},{"location":"parametric/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Functions to estimate time series long memory models by parametric methods. Of particular interest is the ARFIMA model. Moreover, a method to estimate the HAR model, a specification usually used as a proxy for long memory dynamics, is also available.","category":"page"},{"location":"parametric/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Modules = [ParametricEstimators]","category":"page"},{"location":"parametric/#LongMemory.ParametricEstimators","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators","text":"ParametricEstimators\n\nThis module contains functions for estimating the parameters of the fractional differenced process à la ARFIMA and the CSA process.\n\nAuthor\n\nJ. Eduardo Vera-Valdés\n\n\n\n\n\n","category":"module"},{"location":"parametric/#LongMemory.ParametricEstimators.csa_cor_vals-Tuple{Int64, Real, Real}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.csa_cor_vals","text":"csa_cor_vals(T::Int, p::Real, q::Real)\n\nComputes the autocorrelation function of the CSA process with parameters p and q at lags 0, 1, ..., T-1.\n\nArguments\n\nT::Int: The number of lags to compute.\np::Real: The first parameter of the CSA process.\nq::Real: The second parameter of the CSA process.\n\nOutput\n\nacf::Array: The autocorrelation function of the CSA process with parameters p and q at lags 0, 1, ..., T-1.\n\nNotes\n\nThis function uses csavarvals() to compute the autocovariance function and then normalizes by the variance (first computed value). \n\nExamples\n\njulia> csa_cor_vals(20, 0.4, 0.6)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.csa_llk-Tuple{Real, Real, Array}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.csa_llk","text":"csa_llk(p::Real, q::Real, x::Array)\n\nComputes the log-likelihood of the CSA process with parameters p and q given the data x.\n\nArguments\n\np::Real: The first parameter of the CSA process.\nq::Real: The second parameter of the CSA process.\nx::Array: The data.\n\nOutput\n\nllk::Real: The log-likelihood of the CSA process with parameters p and q given the data x.\n\nNotes\n\nThis function computes the concentrated log-likelihood function of the CSA process with parameters p and q given the data x.\n\nExamples\n\njulia> csa_llk(1.4, 1.8, randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.csa_mle_est-Tuple{Array}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.csa_mle_est","text":"csa_mle_est(x::Array)\n\nComputes the maximum likelihood estimate of the parameters p and q of the CSA process and the variance of the CSA process given the data x.\n\nArguments\n\nx::Array: The data.\n\nOutput\n\np::Real: The maximum likelihood estimate of the first parameter of the CSA process.\nq::Real: The maximum likelihood estimate of the second parameter of the CSA process.\nσ2::Real: The maximum likelihood estimate of the variance of the CSA process.\n\nNotes\n\nThis function uses the Optim package to minimize the log-likelihood function.\n\nExamples\n\njulia> csa_mle_est(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.csa_var_matrix-Tuple{Int64, Real, Real}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.csa_var_matrix","text":"csa_var_matrix(T::Int, d::Real)\n\nConstructs the autocovariance matrix of the CSA process with parametersp and q at lags 0, 1, ..., T-1.\n\nArguments\n\nT::Int: The number of lags to compute.\np::Real: The first parameter of the CSA process.\nq::Real: The second parameter of the CSA process.\n\nOutput\n\nV::Array: The autocovariance matrix of the CSA process with parameters p and q at lags 0, 1, ..., T-1.\n\nExamples\n\njulia> csa_var_matrix(10, 1.4, 1.8)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.csa_var_vals-Tuple{Int64, Real, Real}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.csa_var_vals","text":"csa_var_vals(T::Int, p::Real, q::Real)\n\nComputes the autocovariance function of the CSA process with parameters p and q at lags 0, 1, ..., T-1.\n\nArguments\n\nT::Int: The number of lags to compute.\np::Real: The first parameter of the CSA process.\nq::Real: The second parameter of the CSA process.\n\nOutput\n\nacf::Array: The autocovariance function of the CSA process with parameters p and q at lags 0, 1, ..., T-1.\n\nNotes\n\nThis function uses the recursive formula for the autocovariance function of the CSA process.\n\nExamples\n\njulia> csa_var_vals(20, 0.4, 0.6)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.fi_cor_vals-Tuple{Int64, Real}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.fi_cor_vals","text":"fi_cor_vals(T::Int,d::Real)\n\nComputes the autocorrelation function of the fractional differenced process with parameter d at lags 0, 1, ..., T-1.\n\nArguments\n\nT::Int: The number of lags to compute.\nd::Real: The fractional differencing parameter.\n\nOutput\n\nvars::Array: The autocorrelation function of the fractional differenced process with parameter d at lags 0, 1, ..., T-1.\n\nNotes\n\nThis function uses fivarvals() to compute the autocovariance function and then normalizes by the variance (first computed value). \n\nExamples\n\njulia> fi_cor_vals(10, 0.4)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.fi_llk-Tuple{Real, Array}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.fi_llk","text":"fi_llk(x::Array,d::Real)\n\nComputes the log-likelihood of the fractional differenced process with parameter d given the data x.\n\nArguments\n\nx::Array: The data.\nd::Real: The fractional differencing parameter.\n\nOutput\n\nllk::Real: The log-likelihood of the fractional differenced process with parameter d given the data x.\n\nNotes\n\nThis function computes the concentrated log-likelihood function of the fractional differenced process with parameter d given the data x. The function is inspired by the arfima.Estimate() function in Ox; see Doornik (1999).\t\n\nExamples\n\njulia> fi_llk(randn(100,1), 0.4)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.fi_mle_est-Tuple{Array}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.fi_mle_est","text":"fi_mle_est(x::Array)\n\nComputes the maximum likelihood estimate of the fractional differencing parameter and the variance of the fractional differenced process given the data x.\n\nArguments\n\nx::Array: The data.\n\nOutput\n\nd::Real: The maximum likelihood estimate of the fractional differencing parameter.\nσ2::Real: The maximum likelihood estimate of the variance of the fractional differenced process.\n\nNotes\n\nThis function uses the Optim package to minimize the log-likelihood function. The function is inspired by the arfima.Estimate() function in Ox; see Doornik (1999).\t\n\nExamples\n\njulia> fi_mle_est(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.fi_var_matrix-Tuple{Int64, Real}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.fi_var_matrix","text":"fi_var_matrix(T::Int, d::Real)\n\nConstructs the autocovariance matrix of the fractional differenced process with parameter d at lags 0, 1, ..., T-1.\n\nArguments\n\nT::Int: The number of lags to compute.\nd::Real: The fractional differencing parameter.\n\nOutput\n\nV::Array: The autocovariance matrix of the fractional differenced process with parameter d at lags 0, 1, ..., T-1.\n\nExamples\n\njulia> fi_var_matrix(10, 0.4)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.fi_var_vals-Tuple{Int64, Real}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.fi_var_vals","text":"fi_var_vals(T::Int,d::Real)\n\nComputes the autocovariance function of the fractional differenced process with parameter d at lags 0, 1, ..., T-1.\n\nArguments\n\nT::Int: The number of lags to compute.\nd::Real: The fractional differencing parameter.\n\nOutput\n\nvars::Array: The autocovariance function of the fractional differenced process with parameter d at lags 0, 1, ..., T-1.\n\nNotes\n\nThis function uses the recursive formula for the autocovariance function of the fractional differenced process. \n\nExamples\n\njulia> fi_var_vals(10, 0.4)\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.har_est-Tuple{Array}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.har_est","text":"har_est(x::Array; m::Array = [1 , 5 , 22])\n\nEstimates the parameters of the Heterogenous Autoregressive (HAR) model given the data x. See Corsi (2009).\n\nArguments\n\nx::Array: The data.\n\nOptional arguments\n\nm::Array: An array with the lags to use in the estimation. By default, the lags are 1, 5, and 22; as suggested by the original paper.\n\nOutput\n\nbetas::Array: The estimated parameters of the HAR model.\nsigma::Real: The estimated variance of the HAR model.\n\nExamples\n\njulia> har_est(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"parametric/#LongMemory.ParametricEstimators.my_toeplitz-Tuple{Array}","page":"Parameter Estimation","title":"LongMemory.ParametricEstimators.my_toeplitz","text":"my_toeplitz(coefs::Array)\n\nConstructs a Toeplitz matrix from the given coefficients.\n\nArguments\n\ncoefs::Array: An array of coefficients.\n\nOutput\n\nToep::Array: The Toeplitz matrix constructed from the given coefficients.\n\nExamples\n\njulia> my_toeplitz([1, 2, 3])\n\n\n\n\n\n","category":"method"},{"location":"parametric/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"about/","page":"Home","title":"Home","text":"CurrentModule = LongMemory","category":"page"},{"location":"about/#Long-Memory","page":"Home","title":"Long Memory","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"about/#Description","page":"Home","title":"Description","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"This package implements functions to generate and estimate time series long memory models.","category":"page"},{"location":"about/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"The package is registered in the Julia registry and can be installed at the REPL with ] add LongMemory.","category":"page"},{"location":"about/#Generation","page":"Home","title":"Generation","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Long Memory Generation contains the documentation for the functions to generate time series long memory models.","category":"page"},{"location":"about/#Log-Periodogram-Based-Estimators","page":"Home","title":"Log-Periodogram-Based Estimators","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Log-Periodogram-Based Estimators for Long Memory contains the documentation for the functions to estimate the long memory parameter based on the log-periodogram regression. Estimators include the Geweke and Porter-Hudak estimators and the Whittle estimator, as well as bias-reduced versions of them.","category":"page"},{"location":"about/#Parametric-Estimation","page":"Home","title":"Parametric Estimation","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Parametric Estimators for Long Memory contains the documentation for the functions to estimate time series long memory models by parametric methods. Of particular interest is the ARFIMA model. Moreover, a method to estimate the HAR model, a specification usually used as a proxy for long memory dynamics, is also available.","category":"page"},{"location":"about/#Classic-Estimation","page":"Home","title":"Classic Estimation","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Classic Estimator for the Hurst Effect contains the documentation for the functions to estimate the rescaled range (R/S) statistic and the Hurst coefficient.","category":"page"},{"location":"about/#Forecasting","page":"Home","title":"Forecasting","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Forecasting Long Memory Processes contains the documentation for the functions to forecast long memory processes using the fractional differencing operator and the cross-sectional aggregation method. Forecasting using the HAR model is also available.","category":"page"},{"location":"about/#List-of-Functions","page":"Home","title":"List of Functions","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Index contains the list of all the functions in the package.","category":"page"},{"location":"about/#Data","page":"Home","title":"Data","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Data Available contains the list of data sets available in the package.","category":"page"},{"location":"about/#Author","page":"Home","title":"Author","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"J. Eduardo Vera-Valdés","category":"page"},{"location":"about/#Report-a-bug","page":"Home","title":"Report a bug","text":"","category":"section"},{"location":"about/","page":"Home","title":"Home","text":"Please, report any bugs here.","category":"page"},{"location":"classicest/","page":"Classic Estimation","title":"Classic Estimation","text":"CurrentModule = LongMemory","category":"page"},{"location":"classicest/#Classic-Estimator-for-the-Hurst-Effect","page":"Classic Estimation","title":"Classic Estimator for the Hurst Effect","text":"","category":"section"},{"location":"classicest/","page":"Classic Estimation","title":"Classic Estimation","text":"Functions to estimate the rescaled range (R/S) statistic and the Hurst coefficient. The estimator is based on the original work by Hurst (1951) and is included for historical reasons. The estimator is not recommended for practical purposes.","category":"page"},{"location":"classicest/","page":"Classic Estimation","title":"Classic Estimation","text":"Modules = [ClassicEstimators]","category":"page"},{"location":"classicest/#LongMemory.ClassicEstimators","page":"Classic Estimation","title":"LongMemory.ClassicEstimators","text":"ClassicEstimators\n\nThis module contains functions to estimate them Hurst coefficient, closely related to the long memory parameter, of a time series using the rescaled range (R/S) statistic.\n\nAuthor\n\nJ. Eduardo Vera-Valdés\n\n\n\n\n\n","category":"module"},{"location":"classicest/#LongMemory.ClassicEstimators.autocorrelation","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.autocorrelation","text":"autocorrelation(x::Array, k::Int; flag::Bool=true)\n\nComputes the autocorrelation function of a time series.\n\nArguments\n\nx::Array: The time series.\nk::Int: The lag of the autocorrelation.\n\nOutput\n\nacf::Array: The autocorrelation function.\n\nOptional arguments\n\nflag::Bool: If true, the autocorrelation function is displayed.\n\nExamples\n\njulia> autocorrelation(randn(100), 10)\n\n\n\n\n\n","category":"function"},{"location":"classicest/#LongMemory.ClassicEstimators.autocorrelation_plot","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.autocorrelation_plot","text":"autocorrelation_plot(x::Array, k::Int)\n\nComputes the autocorrelation function of a time series.\n\nArguments\n\nx::Array: The time series.\nk::Int: The lag of the autocorrelation.\n\nOutput\n\np1::Plots.Plot: The autocorrelation function.\n\nExamples\n\njulia> autocorrelation_plot(randn(100), 10)\n\n\n\n\n\n","category":"function"},{"location":"classicest/#LongMemory.ClassicEstimators.autocovariance-Tuple{Array, Int64}","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.autocovariance","text":"autocovariance(x::Array, k::Int)\n\nComputes the autocovariance of a time series.\n\nArguments\n\nx::Array: The time series.\nk::Int: The lag of the autocovariance.\n\nOutput\n\nacv::Array: The autocovariance.\n\nExamples\n\njulia> autocovariance(randn(100), 2)\n\n\n\n\n\n","category":"method"},{"location":"classicest/#LongMemory.ClassicEstimators.rescaled_range-Tuple{Array}","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.rescaled_range","text":"rescaled_range(x::Array)\n\nComputes the rescaled range (R/S) statistic of a time series.\n\nArguments\n\nx::Array: The time series.\n\nOutput\n\nRS::Array: The rescaled range statistic.\n\nExamples\n\njulia> rescaled_range(randn(100))\n\n\n\n\n\n","category":"method"},{"location":"classicest/#LongMemory.ClassicEstimators.rescaled_range_est-Tuple{Array}","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.rescaled_range_est","text":"rescaled_range_est(x::Array)\n\nEstimates the Hurst coefficient of a time series using the rescaled range (R/S) statistic.\n\nArguments\n\nx::Array: The time series.\n\nOutput\n\nH::Real: The estimated Hurst coefficient.\n\nNotes\n\nThis function uses the linear regression method on the log of the rescaled range to estimate the Hurst coefficient. The Hurst coefficient is related to the long memory parameter d by the formula H = d + 1/2.\n\nExamples\n\njulia> rescaled_range_est(randn(100))\n\n\n\n\n\n","category":"method"},{"location":"classicest/#LongMemory.ClassicEstimators.smean-Tuple{Array}","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.smean","text":"smean(x::Array)\n\nComputes the sample mean of a time series.\n\nArguments\n\nx::Array: The time series.\n\nOutput\n\nmean::Real: The sample mean.\n\nExamples\n\njulia> smean(randn(100))\n\n\n\n\n\n","category":"method"},{"location":"classicest/#LongMemory.ClassicEstimators.sstd-Tuple{Array}","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.sstd","text":"sstd(x::Array; k::Int=0)\n\nComputes the sample standard deviation of a time series.\n\nArguments\n\nx::Array: The time series.\n\nOutput\n\nstd::Real: The sample standard deviation.\n\nOptional arguments\n\nk::Int: The bias-correction term.\n\nNotes\n\nThis function divides by T instead of T-1 if no bias-correction term is provided.\n\nExamples\n\njulia> sstd(randn(100))\n\n\n\n\n\n","category":"method"},{"location":"classicest/#LongMemory.ClassicEstimators.sstdk","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.sstdk","text":"sstdk(x::Array, k::Int)\n\nComputes the sample standard deviation of a time series using the k-th order sample mean.\n\nArguments\n\nx::Array: The time series.\nk::Int: The order of the sample mean.\n\nOutput\n\nstd::Real: The sample standard deviation.\n\nExamples\n\njulia> sstdk(randn(100), 2)\n\n\n\n\n\n","category":"function"},{"location":"classicest/#LongMemory.ClassicEstimators.variance_plot-Tuple{Array}","page":"Classic Estimation","title":"LongMemory.ClassicEstimators.variance_plot","text":"variance_plot(x::Array; flag::Bool=true, slope::Bool=true)\n\nComputes the variance plot of a time series and estimates the Hurst coefficient.\n\nArguments\n\nx::Array: The time series.\n\nOutput\n\nd_var::Real: The estimated long memory parameter computed as (beta+1)/2, where beta is the slope of the linear regression of the log of the variance plot.\n\nOptional arguments\n\nflag::Bool: If true, the variance plot is displayed.\nslope::Bool: If true, the slope of the linear regression is displayed.\n\nNotes\n\nThis function uses the linear regression method on the log of the variance plot to estimate the long memory parameter.\n\nExamples\n\njulia> variance_plot(randn(100))\n\n\n\n\n\n","category":"method"},{"location":"classicest/","page":"Classic Estimation","title":"Classic Estimation","text":"Hurst, H.E. (1951). Long-term storage capacity of reservoirs. Transactions of the American Society of Civil Engineers, 116, 770-799.","category":"page"},{"location":"classicest/","page":"Classic Estimation","title":"Classic Estimation","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"generating/#Long-Memory-Generation","page":"Generating Functions","title":"Long Memory Generation","text":"","category":"section"},{"location":"generating/","page":"Generating Functions","title":"Generating Functions","text":"Functions to generate time series long memory models. Methods include fractional differencing, error duration model, and à la cross-sectional aggregation.","category":"page"},{"location":"generating/","page":"Generating Functions","title":"Generating Functions","text":"CurrentModule = LongMemory","category":"page"},{"location":"generating/","page":"Generating Functions","title":"Generating Functions","text":"Modules = [GeneratingFunctions]","category":"page"},{"location":"generating/#LongMemory.GeneratingFunctions","page":"Generating Functions","title":"LongMemory.GeneratingFunctions","text":"GeneratingFunctions\n\nThis module contains functions to generate time series with long memory.\n\nAuthor\n\nJ. Eduardo Vera-Valdés\n\n\n\n\n\n","category":"module"},{"location":"generating/#LongMemory.GeneratingFunctions.arfi_gen-Tuple{Int64, Real, Any, Real}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.arfi_gen","text":"arfi_gen(T::Int, μ::Real, AR::Array, d::Real; σ=1)\n\nGenerate a time series with long memory parameter d and length T using the ARFIMA(p,d,0) model.\n\nArguments\n\nT::Int: length of the time series\nμ::Float64: mean of the time series\nAR::Array: AR coefficients\nd::Float64: fractional difference parameter\n\nOptional arguments\n\nσ::Float64: standard deviation of the time series\n\nOutput\n\nx::Vector: time series with long memory\n\nNotes\n\nThe code is inspired by the function dgp_arfima.m by Carlos Vladimir Rodríguez Caballero (2023)\n\nExamples\n\njulia> arfi_gen(100, 0, [0.2; -0.5], 0.4])\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.arfima_gen-Tuple{Int64, Real, Array, Real, Array}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.arfima_gen","text":"arfima_gen(T::Int, μ::Real, AR::Array, d::Real, MA::Array; σ=1)\n\nGenerate a time series with long memory parameter d and length T using the ARFIMA(p,d,q) model.\n\nArguments\n\nT::Int: length of the time series\nμ::Float64: mean of the time series\nAR::Array: AR coefficients\nd::Float64: fractional difference parameter\nMA::Array: MA coefficients\n\nOptional arguments\n\nσ::Float64: standard deviation of the time series\n\nOutput\n\nx::Vector: time series with long memory\n\nNotes\n\nThe code is inspired by the function dgp_arfima.m by Carlos Vladimir Rodríguez Caballero (2023)\n\nExamples\n\njulia> arfima_gen(100, 0, [0.2; -0.5], 0.4, [-0.3; 0.1]])\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.csa_gen-Tuple{Int64, Any, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.csa_gen","text":"csa_gen(T::Int,p,q;μ=0,σ=1)\n\nGenerate a time series with long memory parameter q and length T using the cross-sectional aggregated process.  See Vera-Valdes(2021) for details.\n\nArguments\n\nT::Int: length of the time series\np::Float64: first parameter of the cross-sectional aggregated process\nq::Float64: second parameter of the cross-sectional aggregated process, which is related to the fractional difference parameter d by q = 2(1-d)\n\nOptional arguments\n\nμ::Float64: mean of the time series\nσ::Float64: standard deviation of the time series\n\nOutput\n\nx::Vector: time series with long memory\n\nExamples\n\njulia> csa_gen(100,1.2,1.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.csa_gen-Tuple{Int64, Int64, Any, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.csa_gen","text":"csa_gen(T::Int,N::Int,p,q;t=0.01;μ=0,σ=1)\n\nGenerate a time series with long memory parameter q and length T using the cross-sectional aggregation of 'N' AR(1) processes à la Granger (1980).\n\nArguments\n\nT::Int: length of the time series\nN::Int: number of AR(1) processes\np::Float64: first parameter of the cross-sectional aggregated process\nq::Float64: second parameter of the cross-sectional aggregated process, which is related to the fractional difference parameter d by q = 2(1-d)\n\nOptional arguments\n\nt::Float64: taper length\nμ::Float64: mean of the time series\nσ::Float64: standard deviation of the time series\n\nNotes\n\nMultiple dispatch is used to generate the finite sample process if 'N' is included in the arguments.\n\nOutput\n\nx::Vector: time series with long memory\n\nExamples\n\njulia> csa_gen(100,100,1.2,1.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.csadiff-Tuple{Array, Any, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.csadiff","text":"csadiff(x,p,q)\n\nGenerate long memory by using the moving average representation of the cross-sectional aggregated process using the fast Fourier algorithm. See Vera-Valdes(2021) for details.\n\nArguments\n\nx::Vector: time series\np::Float64: first parameter of the cross-sectional aggregated process\nq::Float64: second parameter of the cross-sectional aggregated process, which is related to the fractional difference parameter d by q = 2(1-d)\n\nOutput\n\ndx::Vector: time series with long memory\n\nNotes\n\nq determines the long memory parameter of the cross-sectional aggregated process. The relation q = 2(1-d) holds, where d is the fractional difference parameter. We use autoregressive formulas to efficiently compute the coefficients of the moving average representation of the cross-sectional aggregated process. \n\nExamples\n\njulia> csadiff(randn(100,1),1.2,1.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.edm_gen-Tuple{Int64, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.edm_gen","text":"edm_gen(T::Int,d; t=0.5, μ=0, σ=1)\n\nGenerate a time series with long memory parameter d and length T using the error duration model à la Parke (1999).\n\nArguments\n\nT::Int: length of the time series\nd::Float64: long memory parameter\n\nOptional arguments\n\nt::Float64: taper length\nμ::Float64: mean of the time series\nσ::Float64: standard deviation of the time series\n\nOutput\n\nx::Vector: time series with long memory\n\nNotes\n\nThe taper length t is the proportion of the time series that is pre-sampled to avoid the initial bias of the error duration model.\n\nExamples\n\njulia> edm_gen(100,0.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.fi-Tuple{Int64, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.fi","text":"fi(T,d;μ=0,σ=1)\n\nGenerate a time series with long memory parameter d and length T using the fractional difference filter.\n\nArguments\n\nT::Int: length of the time series\nd::Float64: fractional difference parameter\n\nOptional arguments\n\nμ::Float64: mean of the time series\nσ::Float64: standard deviation of the time series\n\nOutput\n\nx::Vector: time series with long memory\n\nNotes\n\nMultiple dispatch is used for generation: If d is an integer, the function returns a time series with first or null difference. See fracdiff for details.\n\nExamples\n\njulia> fi(100,0.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.fi_gen-Tuple{Int64, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.fi_gen","text":"fi_gen(T,d;μ=0,σ=1)\n\nGenerate a time series with long memory parameter d and length T using the fractional difference filter.\n\nArguments\n\nT::Int: length of the time series\nd::Float64: fractional difference parameter\n\nOptional arguments\n\nμ::Float64: mean of the time series\nσ::Float64: standard deviation of the time series\n\nOutput\n\nx::Vector: time series with long memory\n\nNotes\n\nMultiple dispatch is used for generation: If d is an integer, the function returns a time series with first or null difference. See fracdiff for details.\n\nExamples\n\njulia> fi_gen(100,0.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.fi_survival_probs-Tuple{Int64, Any}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.fi_survival_probs","text":"\"     fisurvivalprobs(N::Int,d)\n\nGenerate the survival probabilities of the error duration model à la Parke (1999).\n\nArguments\n\nN::Int: length of the time series\nd::Float64: fractional difference parameter\n\nOutput\n\np::Vector: survival probabilities\n\nNotes\n\nThe survival probabilities are computed using the recursive formula p_{t+1} = p_t * (t + d - 1) / (t + 1 - d) to avoid numerical overflow.\n\nExamples\n\njulia> fi_survival_probs(100,0.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.fracdiff-Tuple{Array, Float64}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.fracdiff","text":"fracdiff(x,d)\n\nCompute the fractional difference of a time series x with fractional order d∈(-1/2,1/2).\n\nArguments\n\nx::Vector: time series\nd::Float64: fractional difference parameter\n\nOutput\n\ndx::Vector: fractional difference of x\n\nNotes\n\nThe function uses the fast Fourier transform to compute the convolution of the time series with the fractional difference filter.  See Jensen and Nielsen (2014) for details. We use autoregressive formulas to efficiently compute the coefficients of the fractional difference filter.\n\nExamples\n\njulia> fracdiff(randn(100,1),0.4)\n\n\n\n\n\n","category":"method"},{"location":"generating/#LongMemory.GeneratingFunctions.fracdiff-Tuple{Array, Int64}","page":"Generating Functions","title":"LongMemory.GeneratingFunctions.fracdiff","text":"fracdiff(x,d::Int)\n\nCompute the first or null difference of a time series x. Multiple dispatch is used to return the same input or call the function diff from the Julia standard library if d=1 or d=0, respectively.\n\nArguments\n\nx::Vector: time series\nd::Int64: difference parameter\n\nOutput\n\ndx::Vector: first or null difference of x\n\nExamples\n\njulia> fracdiff(randn(100,1),1)\n\n\n\n\n\n","category":"method"},{"location":"generating/","page":"Generating Functions","title":"Generating Functions","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"logperiod/","page":"Log-Periodogram Estimation","title":"Log-Periodogram Estimation","text":"CurrentModule = LongMemory","category":"page"},{"location":"logperiod/#Log-Periodogram-Based-Estimators-for-Long-Memory","page":"Log-Periodogram Estimation","title":"Log-Periodogram-Based Estimators for Long Memory","text":"","category":"section"},{"location":"logperiod/","page":"Log-Periodogram Estimation","title":"Log-Periodogram Estimation","text":"Functions to estimate the long memory parameter based on the log-periodogram regression.  Estimators include the Geweke and Porter-Hudak estimators and the Whittle estimator.","category":"page"},{"location":"logperiod/","page":"Log-Periodogram Estimation","title":"Log-Periodogram Estimation","text":"Modules = [LogPeriodEstimators]","category":"page"},{"location":"logperiod/#LongMemory.LogPeriodEstimators","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators","text":"LogPeriodEstimators\n\nThis module contains functions to estimate the long memory parameter of a time series using the log-periodogram estimator and the Whittle log-likelihood function.\n\nAuthor\n\nJ. Eduardo Vera-Valdés\n\n\n\n\n\n","category":"module"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.exact_whittle_est-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.exact_whittle_est","text":"exact_whittle_est(x::Array; m=0.5, l=0)\n\nEstimate the long memory parameter of a time series x using the exact Whittle log-likelihood function. See Shimotsu and Phillips (2005) for details.\n\nArguments\n\nx::Vector: time series\nm∈(0,1)::Float64: taper final\nl∈(0,1)::Float64: taper initial\n\nOutput\n\nd::Float64: long memory parameter\n\nNotes\n\nThe function considers the periodogram of the time series x for frequencies in the interval [T^l,T^m]. The zero frequency is always excluded. The condition m < l must hold. The default values of m and l are 0.5 and 0, respectively.\n\nExamples\n\njulia> exact_whittle_est(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.exact_whittle_llk-Tuple{Any, Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.exact_whittle_llk","text":"exact_whittle_llk(d, x::Array; m=0.5, l=0)\n\nCompute the exact Whittle log-likelihood function of a time series x for a given long memory parameter d. See Shimotsu and Phillips (2005) for details.\n\nArguments\n\nd::Float64: long memory parameter\nx::Vector: time series\nm∈(0,1)::Float64: taper final\nl∈(0,1)::Float64: taper initial\n\nOutput\n\nQ::Float64: Whittle log-likelihood function\n\nNotes\n\nThe function considers the periodogram of the time series x for frequencies in the interval [T^l,T^m]. The zero frequency is always excluded. The condition m < l must hold. The default values of m and l are 0.5 and 0, respectively.\n\nExamples\n\njulia> exact_whittle_llk(0.4,randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.gph_est-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.gph_est","text":"gph_est(x::Array; m=0.5, l=0, br=0::Int)\n\nEstimate the long memory parameter of a time series x using the log-periodogram estimator. See Geweke and Porter-Hudak (1983) and Andrews and Guggenberger (2003) for details.\n\nArguments\n\nx::Vector: time series\nm∈(0,1)::Float64: taper final\nl∈(0,1)::Float64: taper initial\nbr::Int64: number of bias reduction terms\n\nOutput\n\nd::Float64: long memory parameter\n\nNotes\n\nThe function considers the periodogram of the time series x for frequencies in the interval [T^l,T^m]. The zero frequency is always excluded. The default values of m and l are 0.5 and 0, respectively. The condition m < l must hold.\n\nThe default value of br is 0 which returns the original GPH log-periodogram estimator.\n\nExamples\n\njulia> gph_est(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.gph_est_variance-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.gph_est_variance","text":"gph_est_variance(x::Array; m=0.5, l=0, br=0::Int)\n\nEstimate the variance of the long memory parameter of a time series x using the log-periodogram estimator. See Geweke and Porter-Hudak (1983) and Andrews and Guggenberger (2003) for details.\n\nArguments\n\nx::Vector: time series\n\nOptional arguments\n\nm∈(0,1)::Float64: taper final\nbr::Int64: number of bias reduction terms\n\nOutput\n\nvarb::Float64: variance of the long memory parameter\n\nNotes\n\nMultiple dispatch is used for computation. If the first input is an integer, the function interprets it as the sample size; otherwise, it computes the sample size from the length of the time series.\n\nExamples\n\njulia> gph_est_variance(fi(100,0.4))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.gph_est_variance-Tuple{Int64}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.gph_est_variance","text":"gph_est_variance(T::Int; m=0.5, l=0, br=0::Int)\n\nEstimate the variance of the long memory parameter of a time series of length T using the log-periodogram estimator. See Geweke and Porter-Hudak (1983) and Andrews and Guggenberger (2003) for details.\n\nArguments\n\nT::Int: length of the time series\n\nOptional arguments\n\nm∈(0,1)::Float64: taper final\nbr::Int64: number of bias reduction terms\n\nOutput\n\nvarb::Float64: variance of the long memory parameter\n\nNotes\n\nMultiple dispatch is used for computation. If the first input is an integer, the function interprets it as the sample size; otherwise, it computes the sample size from the length of the time series.\n\nExamples\n\njulia> gph_est_variance(100,0.4)\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.periodogram-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.periodogram","text":"periodogram(x::Array)\n\nCompute the periodogram of a time series x using the fast Fourier transform.\n\nArguments\n\nx::Vector: time series\n\nOutput\n\nI_w::Vector: periodogram\nw::Vector: Fourier frequencies\n\nExamples\n\njulia> periodogram(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.periodogram_plot-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.periodogram_plot","text":"periodogram_plot(x::Array; slope::Bool=true)\n\nPlots the log-periodogram of a time series x.\n\nArguments\n\nx::Vector: time series\n\nOutput\n\np1::Plots.Plot: log-periodogram\n\nOptional arguments\n\nslope::Bool: If true, the slope of the linear regression is displayed.\n\nExamples\n\njulia> periodogram_plot(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.whittle_est-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.whittle_est","text":"whittle_est(x::Array; m=0.5, l=0)\n\nEstimate the long memory parameter of a time series x using the Whittle log-likelihood function. See Künsch (1987) for details.\n\nArguments\n\nx::Vector: time series\nm∈(0,1)::Float64: taper final\nl∈(0,1)::Float64: taper initial\n\nOutput\n\nd::Float64: long memory parameter\n\nNotes\n\nThe function considers the periodogram of the time series x for frequencies in the interval [T^l,T^m]. The zero frequency is always excluded. The condition m < l must hold. The default values of m and l are 0.5 and 0, respectively.\n\nExamples\n\njulia> whittle_est(randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.whittle_est_variance-Tuple{Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.whittle_est_variance","text":"whittle_est_variance(x::Array; m=0.5)\n\nEstimate the variance of the estimator for the long memory parameter of a time series x using the Whittle log-likelihood function. See Künsch (1987) for details.\n\nArguments\n\nx::Vector: time series\n\nOptional arguments\n\nm∈(0,1)::Float64: taper final\n\nOutput\n\nvarb::Float64: variance of the estimator\n\nNotes\n\nMultiple dispatch is used for computation. If the first input is an integer, the function interprets it as the sample size; otherwise, it computes the sample size from the length of the time series.     The variance is the same as the one from using the exact Whittle log-likelihood function.\n\nExamples\n\njulia> whittle_est_variance(fi(100,0.4))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.whittle_est_variance-Tuple{Int64}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.whittle_est_variance","text":"whittle_est_variance(T::Int;m=0.5\n\nEstimate the variance of the estimator for the long memory parameter of a time series of length T using the Whittle log-likelihood function. See Künsch (1987) for details.\n\nArguments\n\nT::Int: length of the time series\n\nOptional arguments\n\nm∈(0,1)::Float64: taper final\n\nOutput\n\nvarb::Float64: variance of the estimator\n\nNotes\n\nMultiple dispatch is used for computation. If the first input is an integer, the function interprets it as the sample size; otherwise, it computes the sample size from the length of the time series. The variance is the same as the one from using the exact Whittle log-likelihood function.\n\nExamples\n\njulia> whittle_est_variance(100,0.4)\n\n\n\n\n\n","category":"method"},{"location":"logperiod/#LongMemory.LogPeriodEstimators.whittle_llk-Tuple{Any, Array}","page":"Log-Periodogram Estimation","title":"LongMemory.LogPeriodEstimators.whittle_llk","text":"whittle_llk(d, x::Array; m=0.5, l=0)\n\nCompute the Whittle log-likelihood function of a time series x for a given long memory parameter d. See Künsch (1987) for details.\n\nArguments\n\nd::Float64: long memory parameter\nx::Vector: time series\nm∈(0,1)::Float64: taper final\nl∈(0,1)::Float64: taper initial\n\nOutput\n\nQ::Float64: Whittle log-likelihood function\n\nNotes\n\nThe function considers the periodogram of the time series x for frequencies in the interval [T^l,T^m]. The zero frequency is always excluded. The condition m < l must hold.  The default values of m and l are 0.5 and 0, respectively.\n\nExamples\n\njulia> whittle_llk(0.4,randn(100,1))\n\n\n\n\n\n","category":"method"},{"location":"logperiod/","page":"Log-Periodogram Estimation","title":"Log-Periodogram Estimation","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"CurrentModule = LongMemory","category":"page"},{"location":"data/#Data-Available","page":"Data Available","title":"Data Available","text":"","category":"section"},{"location":"data/","page":"Data Available","title":"Data Available","text":"The package includes the following data sets:","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"Nile River Minima (622-1284). Available as NileRiverMin.csv.","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"The Nile River Minima contains the following columns:","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"Year: Year of the observation.\nNileMin: Value of the observation.","category":"page"},{"location":"data/#Loading-the-Data","page":"Data Available","title":"Loading the Data","text":"","category":"section"},{"location":"data/","page":"Data Available","title":"Data Available","text":"The data are stored in CSV files as DataFrame.","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"Hence, loading the data requires the CSV.jl and DataFrames.jl packages.","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"You can load the data sets with the following commands:","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"using LongMemory\nusing CSV, DataFrames\nNileMin = CSV.read(\"examples/NileRiverMin.csv\",DataFrame)","category":"page"},{"location":"data/","page":"Data Available","title":"Data Available","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"","page":"Index","title":"Index","text":"CurrentModule = LongMemory","category":"page"},{"location":"#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"","page":"Index","title":"Index","text":"Documentation for LongMemory.jl.","category":"page"},{"location":"","page":"Index","title":"Index","text":"","category":"page"},{"location":"forecasting/#Forecasting-Long-Memory-Processes","page":"Forecasting","title":"Forecasting Long Memory Processes","text":"","category":"section"},{"location":"forecasting/","page":"Forecasting","title":"Forecasting","text":"Functions to forecast long memory processes using the fractional differencing operator and the cross-sectional aggregation method. Forecasting using the HAR model is also available.","category":"page"},{"location":"forecasting/","page":"Forecasting","title":"Forecasting","text":"CurrentModule = LongMemory","category":"page"},{"location":"forecasting/","page":"Forecasting","title":"Forecasting","text":"Modules = [Forecasters]","category":"page"},{"location":"forecasting/#LongMemory.Forecasters","page":"Forecasting","title":"LongMemory.Forecasters","text":"Forecasters\n\nThis module contains functions to forecast a long memory time series using the fractional differencing method and the CSA method.\n\nAuthor\n\nJ. Eduardo Vera-Valdés\n\n\n\n\n\n","category":"module"},{"location":"forecasting/#LongMemory.Forecasters.csa_forecast-Tuple{Array, Int64, Real, Real, Real}","page":"Forecasting","title":"LongMemory.Forecasters.csa_forecast","text":"csa_forecast(x::Array, h::Int, p::Real, q::Real, σ::Real)\n\nComputes the forecast of a long memory time series using the CSA method.\n\nArguments\n\nx::Array: The time series.\nh::Int: The number of periods to forecast.\np::Real: The parameter p of the CSA process.\nq::Real: The parameter q of the CSA process.\nσ::Real: The standard deviation of the forecast errors.\n\nOutput\n\nxfor::Array: The forecast of the time series as a matrix where the first column is the forecast, the second column is the lower confidence band, and the third column is the upper confidence band. The first T elements are the original time series.\n\nNotes\n\nMultiple dispatch is used to compute the forecast of a time series with or without confidence bands.\n\nExamples\n\njulia> csa_forecast(csafigen(100,1.4,1.4), 10, 1.4, 1.4, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"forecasting/#LongMemory.Forecasters.csa_forecast-Tuple{Array, Int64, Real, Real}","page":"Forecasting","title":"LongMemory.Forecasters.csa_forecast","text":"csa_forecast(x::Array, h::Int, p::Real, q::Real)\n\nComputes the forecast of a long memory time series using the CSA method.\n\nArguments\n\nx::Array: The time series.\nh::Int: The number of periods to forecast.\np::Real: The parameter p of the CSA process.\nq::Real: The parameter q of the CSA process.\n\nOutput\n\nxfor::Array: The forecast of the time series as a column vector. The first T elements are the original time series.\n\nNotes\n\nMultiple dispatch is used to compute the forecast of a time series with or without confidence bands.\n\nExamples\n\njulia> csa_forecast(csafigen(100,1.4,1.4), 10, 1.4, 1.4)\n\n\n\n\n\n","category":"method"},{"location":"forecasting/#LongMemory.Forecasters.csa_ma_coefs-Tuple{Real, Real, Int64}","page":"Forecasting","title":"LongMemory.Forecasters.csa_ma_coefs","text":"csa_ma_coefs(p::Real, q::Real, maxlags::Int)\n\nComputes the MA coefficients of the CSA process with parameters p and q at lags 0, ..., maxlags-1.\n\nArguments\n\np::Real: The parameter p of the CSA process.\nq::Real: The parameter q of the CSA process.\nmaxlags::Int: The number of lags to compute.\n\nOutput\n\nma_coefs::Array: The MA coefficients of the CSA process with parameters p and q at lags 0, ..., maxlags-1.\n\nNotes\n\nThe MA coefficients are computed using the recursive formula for speed. The zero lag coefficient is included, it is theoretically 1.\n\nExamples\n\njulia> csa_ma_coefs(1.4, 1.4, 5)\n\n\n\n\n\n","category":"method"},{"location":"forecasting/#LongMemory.Forecasters.fi_ar_coefs-Tuple{Real, Int64}","page":"Forecasting","title":"LongMemory.Forecasters.fi_ar_coefs","text":"fi_ar_coefs(d::Real, maxlags::Int)\n\nComputes the AR coefficients of the fractional differenced process with parameter d at lags 1, ..., maxlags.\n\nArguments\n\nd::Real: The fractional differencing parameter.\nmaxlags::Int: The number of lags to compute.\n\nOutput\n\nar_coefs::Array: The AR coefficients of the fractional differenced process with parameter d at lags 1, ..., maxlags.\n\nNotes\n\nThe AR coefficients are computed using the recursive formula for speed. The zero lag coefficient is not computed, it is theoretically 1.\n\nExamples\n\njulia> fi_ar_coefs(0.2, 5)\n\n\n\n\n\n","category":"method"},{"location":"forecasting/#LongMemory.Forecasters.fi_forecast-Tuple{Array, Int64, Real, Real}","page":"Forecasting","title":"LongMemory.Forecasters.fi_forecast","text":"fi_forecast(x::Array, h::Int, d::Real, σ::Real)\n\nComputes the forecast of a long memory time series using the fractional differencing method.\n\nArguments\n\nx::Array: The time series.\nh::Int: The number of periods to forecast.\nd::Real: The fractional differencing parameter.\nσ::Real: The standard deviation of the forecast errors.\n\nOutput\n\nxfor::Array: The forecast of the time series as a matrix where the first column is the forecast, the second column is the lower confidence band, and the third column is the upper confidence band. The first T elements are the original time series.\n\nNotes\n\nMultiple dispatch is used to compute the forecast of a time series with or without confidence bands.\n\nExamples\n\njulia> fi_forecast(figen(100,0.2), 10, 0.2)\n\n\n\n\n\n","category":"method"},{"location":"forecasting/#LongMemory.Forecasters.fi_forecast-Tuple{Array, Int64, Real}","page":"Forecasting","title":"LongMemory.Forecasters.fi_forecast","text":"fi_forecast(x::Array, h::Int, d::Real)\n\nComputes the forecast of a long memory time series using the fractional differencing method.\n\nArguments\n\nx::Array: The time series.\nh::Int: The number of periods to forecast.\nd::Real: The fractional differencing parameter.\n\nOutput\n\nxfor::Array: The forecast of the time series as a column vector. The first T elements are the original time series.\n\nNotes\n\nMultiple dispatch is used to compute the forecast of a time series with or without confidence bands.\n\nExamples\n\njulia> fi_forecast(figen(100,0.2), 10, 0.2)\n\n\n\n\n\n","category":"method"},{"location":"forecasting/#LongMemory.Forecasters.har_forecast","page":"Forecasting","title":"LongMemory.Forecasters.har_forecast","text":"har_forecast(x::Array, h::Int, σ::Real, m::Array=[1,5,22])\n\nComputes the forecast of a time series by fitting and recursevely forecasting the HAR model.\n\nArguments\n\nx::Array: The time series.\nh::Int: The number of periods to forecast.\nσ::Real: The standard deviation of the forecast errors.\n\nOutput\n\nxfor::Array: The forecast of the time series as a matrix where the first column is the forecast, the second column is the lower confidence band, and the third column is the upper confidence band. The first T-max(m) elements are the original time series.\n\nOptional Arguments\n\nm::Array: The lags to include in the HAR model. The default is [1,5,22].\n\nExamples\n\njulia> har_forecast(figen(100,0.2), 10, 1)\n\n\n\n\n\n","category":"function"},{"location":"forecasting/#LongMemory.Forecasters.har_forecast-2","page":"Forecasting","title":"LongMemory.Forecasters.har_forecast","text":"har_forecast(x::Array, h::Int, m::Array=[1,5,22])\n\nComputes the forecast of a time series by fitting and recursevely forecasting the HAR model.\n\nArguments\n\nx::Array: The time series.\nh::Int: The number of periods to forecast.\n\nOutput\n\nxfor::Array: The forecast of the time series as a column vector. The first T-max(m) elements are the original time series.\n\nOptional Arguments\n\nm::Array: The lags to include in the HAR model. The default is [1,5,22].\n\nExamples\n\njulia> har_forecast(figen(100,0.2), 10)\n\n\n\n\n\n","category":"function"},{"location":"forecasting/#LongMemory.Forecasters.my_half_toeplitz-Tuple{Array}","page":"Forecasting","title":"LongMemory.Forecasters.my_half_toeplitz","text":"my_half_toeplitz(coefs::Array)\n\nConstructs a bottom Toeplitz matrix from the given coefficients.\n\nArguments\n\ncoefs::Array: An array of coefficients.\n\nOutput\n\nToep::Array: The bottom Toeplitz matrix constructed from the given coefficients.\n\nExamples\n\njulia> my_half_toeplitz([1, 2, 3])\n\n\n\n\n\n","category":"method"},{"location":"forecasting/","page":"Forecasting","title":"Forecasting","text":"Documentation for LongMemory.jl.","category":"page"}]
}
